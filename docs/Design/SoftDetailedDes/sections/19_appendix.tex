\section{Appendix} \label{Appendix}


\newpage{}

\section*{Appendix --- Reflection}

The information in this section will be used to evaluate the team members on the
graduate attribute of Problem Analysis and Design.

\input{../../Reflection.tex}

\begin{enumerate}
  \item What went well while writing this deliverable?
    \begin{itemize}
      \item \textbf{Aidan Froggatt:}  
      For me, the deliverable went well because I already had strong familiarity with our codebase and architectural decisions. Since I set up the initial project foundation---Turborepo structure, tRPC API, database schema, and BetterAuth configuration---I had a clear understanding of how the modules needed to be defined and integrated. This made it easier to produce accurate, consistent MIS entries. I also found that working through each module clarified how our system would scale and how responsibilities should be divided, which improved the overall coherence of the document.

      \item \textbf{Swesan:} 
      The previous documents (such as the SRS and the earlier drafts) had already established much of the conceptual groundwork, which made defining the modules relatively straightforward. Since we entered this deliverable with a strong understanding of the system's structure, identifying responsibilities and writing the Module Guide flowed naturally. I personally worked on Section 5 (Module Hierarchy) and Section 7, and having those earlier documents as references made the process efficient and focused.

      \item \textbf{[Burhanuddin Kharodawala]:}  
    We had a good discussion as a group which helped me develop a better understanding of the overall content of this deliverable. Moreover, the template had clear understandings for most of the sections I worked on. 
    \end{itemize} 

  \item What pain points did you experience during this deliverable, and how
    did you resolve them?
    \begin{itemize}
      \item \textbf{Aidan Froggatt:}  
      One of the main challenges for me was determining the correct level of abstraction for each module. Because I am so close to the actual implementation, it was easy to accidentally include too many low-level details. I had to step back and focus on "what" the module exposes rather than "how" it works internally. Another pain point was aligning terminology with the Module Guide---for example, ensuring naming consistency and clearly defining frontend, backend, and data responsibilities. I resolved these issues by revisiting the SRS and MG structure and adjusting my MIS sections to fit the expected style and rigor of the course.

      \item \textbf{Swesan:}  
       One of the main challenges was determining which modules were truly necessary and how to group or separate functionality without creating modules that were too abstract or too fragmented. Our initial draft had 15 modules, but after careful discussion and iterative refinement, we narrowed it down to 12 well-defined modules that better reflect the system's actual behaviour and design principles. We resolved this by comparing responsibilities, identifying overlaps, and merging modules where appropriate while ensuring each remaining module had a clear secret, purpose, and boundary.   

      \item \textbf{[Burhanuddin Kharodawala]:}  
      The document had a few ambiguous instructions which I had difficulty understanding. The module decomposition section especially was the one thing that was a little confusing. I was unsure of what the expectations were for the module. As in, what is a module (A feature or functionality)? At the end of the TA meeting however, I was able to discuss this with the TA and confirm the expectations for the modules.     
    \end{itemize}

  \item Which of your design decisions stemmed from speaking to your client(s)
  or a proxy (e.g. your peers, stakeholders, potential users)? For those that
  were not, why, and where did they come from?

  As a team, many of our design choices originated from discussions with peers and user proxies. The idea to create a McMaster-only ridesharing platform emerged from user concerns around safety and trust. Our matching approach, including the swipe-based interface, was influenced by peer feedback indicating that a familiar interaction model would improve adoption.  
  Other decisions---such as using tRPC, BetterAuth, and Drizzle ORM---came from internal technical reasoning. These choices focused on maintainability, type safety, and long-term scalability rather than direct stakeholder input.


  \item While creating the design doc, what parts of your other documents (e.g.
  requirements, hazard analysis, etc), it any, needed to be changed, and why?

  During the MIS development, the team identified minor inconsistencies between the Module Guide, SRS, and earlier architectural descriptions. Some module names were standardized to ensure consistent referencing, and inter-module relationships were clarified, particularly for Matching, Scheduling, and Notification. A few requirement identifiers were refined to improve traceability. No core requirements changed, but descriptions were tightened to align with the finalized MIS structure.

  \item What are the limitations of your solution?  Put another way, given
  unlimited resources, what could you do to make the project better? (LO\_ProbSolutions)

  The current solution, while well-structured, is limited by capstone scope and development time. Our matching algorithm is deterministic and rule-based; with more resources, the team would implement machine-learning-driven adaptive matching.  
  Additional improvements could include:
  \begin{itemize}
      \item fully implemented CI/CD pipelines for automated testing and deployment,
      \item real-time route optimization using live traffic data,
      \item enhanced accessibility and UX refinement,
      \item automated moderation tools and trust scoring systems,
      \item end-to-end encryption and advanced safety features.
  \end{itemize}
  These expansions would elevate Hitchly from a functional prototype to a production-ready system.

  \item Give a brief overview of other design solutions you considered.  What
  are the benefits and tradeoffs of those other designs compared with the chosen
  design?  From all the potential options, why did you select the documented design?
  
  The team considered multiple architectural and implementation approaches. One option was to use a REST-based backend instead of tRPC, but this offered weaker type safety across the mobile app and API. Another option was building a native iOS/Android app, but Expo provided faster development and easier integration within the monorepo.  
  The team also explored using a monolithic architecture versus a modular service structure. Ultimately, the chosen modular design offered the best balance between clarity, extensibility, and meeting course expectations.  
  Alternative matching designs, such as a manually curated list instead of a scoring algorithm, were rejected because they reduced flexibility and diminished the quality of the user matching experience.  

  
  (LO\_Explores)
\end{enumerate}
